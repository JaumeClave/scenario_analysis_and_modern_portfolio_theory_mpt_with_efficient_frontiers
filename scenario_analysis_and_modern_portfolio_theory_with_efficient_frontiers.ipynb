{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Analysis, Delta-Vega-Gamma Approximations and Efficient Frontiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario Analysis and Modern Portfolio Theory with Python by Jaume Clave  \n",
    "May 17, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper begins with a scenario analysis involving three large market index securities. Scenario analysis is important a priori information to a risk or portfolio manager and helps to control the effect of price changes to a portfolio, especially those of potential market crashes. The project continues with an investigation of the mean-variance analysis of Markowitz (1952) when there is no risk-free asset and then move on to the case where there is a risk-free asset available. We also discuss the difficulties of implementing mean-variance analysis in practice and outline some approaches for resolving these difficulties. Because optimal asset allocations are typically very sensitive to estimates of expected returns and covariances, these approaches typically involve superior or more robust parameter estimation methods.\n",
    "\n",
    "This project introduces important terminology used in the financial industry relevant for scenario analysis, profit and loss approximations, portfolio simulations and efficient frontiers. Each section contains code use to transform raw data into tables and visualizations that help understand and interpret the theory. Mathematical expressions are derived where appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Scenario Analysis I](#Scenario-Analysis-I)   \n",
    "i. [Scenario Analysis](#Scenario-Analysis)  \n",
    "i. [Pivot Table](#Pivot-Table)   \n",
    "ii. [S&P 500 Pivot Table](#S&P-500-Pivot-Table)\n",
    "\n",
    "[Delta-Vega-Gamma Approximations and Scenario Analysis II](#Delta-Vega-Gamma-Approximations-and-Scenario-Analysis-II)  \n",
    "i. [Market Index](#Market-Index)  \n",
    "ii. [S&P 500 Index](#S&P-500-Index)  \n",
    "iii. [SX5E Index](#SX5E-Index)   \n",
    "iv. [NKY Index](#NKY-Index)  \n",
    "v. [Total Delta](#Total-Delta)  \n",
    "vi. [Total Gamma](#Total-Gamma)  \n",
    "vii. [Total Vega 1%](#Total-Vega-1%)  \n",
    "viii. [Comparing P&L to Pivot-Table P&L D-G-V Approximation](#Comparing-P&L-to-Pivot-Table-P&L-D-G-V-Approximation)\n",
    "\n",
    "[Simulation and Construction of Actual, Estimated and True Efficient Frontiers](#Simulation-and-Construction-of-Actual,-Estimated-and-True-Efficient-Frontiers)  \n",
    "i. [Generating 5 Years of Monthly Returns with multivariate_normal](#Generating-5-Years-of-Monthly-Returns-with-multivariate_normal)  \n",
    "ii. [Covariance Matrix](#Covariance-Matrix)  \n",
    "iii. [Expected (Realized) Efficient Frontier](#Expected-(Realized)-Efficient-Frontier)  \n",
    "iv. [Modern Portfolio Theory](#Modern-Portfolio-Theory)  \n",
    "v. [Diversification](#Diversification)  \n",
    "vi. [Sharpe Ratio](#Sharpe-Ratio)   \n",
    "vii. [Efficient Frontier with no Risk-Free Asset](#Efficient-Frontier-with-no-Risk-Free-Asset)  \n",
    "viii. [Actual Frontier](#Actual-Frontier)  \n",
    "ix. [True Frontier](#True-Frontier)  \n",
    "x. [Actual, Estimated, and True Frontier](#Actual,-Estimated,-and-True-Frontier)  \n",
    "xi. [Problems with Traditional Mean-Variance Analysis](#Problems-with-Traditional-Mean-Variance-Analysis)  \n",
    "\n",
    "[Conclusion](#Conclusion)  \n",
    "[Further Reading](#Further-Reading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Analysis I\n",
    "This section introduces the concept of scenario analysis and ultimately constructs a pivot-table showing the total P&L in each scenario for all securities with the S&P 500 as the underlying security. The data is initially explored and correlations are visualised by correlation heatmaps. Data is then aggregated and presented using the pandas pivot_table method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'StressData.csv' does not exist: b'StressData.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d467029b62f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Import data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'StressData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'StressData.csv' does not exist: b'StressData.csv'"
     ]
    }
   ],
   "source": [
    "## Import data\n",
    "data = pd.read_csv('StressData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the file contains data on a particular security (option or futures contract) that arises from a particular scenario. The scenarios that were considered are all combinations of the underlying moving by {±20%, ±10%, ±5%, ±2%, ±1%, 0%} and implied volatilities moving by {±10, ±5, ±2, ±1, 0} percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3a137282ae5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstress_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The dataset has {stress_data.shape[0]} rows and {stress_data.shape[1]} columns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstress_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "stress_data = data.copy()\n",
    "print(f'The dataset has {stress_data.shape[0]} rows and {stress_data.shape[1]} columns')\n",
    "stress_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatting column types function\n",
    "def format_df(dataframe):\n",
    "    dataframe.replace(',', '', regex = True, inplace = True)\n",
    "\n",
    "    for col in dataframe.columns:\n",
    "        try:\n",
    "            dataframe[col] = dataframe[col].astype(int)\n",
    "        except:\n",
    "            print(f'{col} was not able to become an int column')\n",
    "\n",
    "    dataframe['Maturity'] = pd.to_datetime(dataframe['Maturity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stress_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-84d07610d4eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Format stress_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mformat_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstress_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stress_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Format stress_data\n",
    "format_df(stress_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stress_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1532c92b68c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Correlation matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstress_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## Create triangle df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stress_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Correlation matrix\n",
    "corr = stress_data.corr()\n",
    "\n",
    "## Create triangle df\n",
    "np.tril(np.ones(corr.shape)).astype(np.bool)[:, :]\n",
    "df_lt = corr.where(np.tril(np.ones(corr.shape)).astype(np.bool))\n",
    "\n",
    "## Plot\n",
    "plt.figure(figsize = (8, 8))\n",
    "ax = sns.heatmap(df_lt, vmin = -1, vmax = 1, center = 0, cmap = sns.diverging_palette(20, 220, n = 200), square = True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to imporve the correlation matrix by building a robust parametrized function that makes heatmaps with sized markers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(x, y, **kwargs):\n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "    else:\n",
    "        color = [1]*len(x)\n",
    "\n",
    "    if 'palette' in kwargs:\n",
    "        palette = kwargs['palette']\n",
    "        n_colors = len(palette)\n",
    "    else:\n",
    "        n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "        palette = sns.color_palette(\"Blues\", n_colors) \n",
    "\n",
    "    if 'color_range' in kwargs:\n",
    "        color_min, color_max = kwargs['color_range']\n",
    "    else:\n",
    "        color_min, color_max = min(color), max(color) \n",
    "    def value_to_color(val):\n",
    "        if color_min == color_max:\n",
    "            return palette[-1]\n",
    "        else:\n",
    "            val_position = float((val - color_min)) / (color_max - color_min) \n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "            return palette[ind]\n",
    "\n",
    "    if 'size' in kwargs:\n",
    "        size = kwargs['size']\n",
    "    else:\n",
    "        size = [1]*len(x)\n",
    "\n",
    "    if 'size_range' in kwargs:\n",
    "        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "    else:\n",
    "        size_min, size_max = min(size), max(size)\n",
    "\n",
    "    size_scale = kwargs.get('size_scale', 500)\n",
    "\n",
    "    def value_to_size(val):\n",
    "        if size_min == size_max:\n",
    "            return 1 * size_scale\n",
    "        else:\n",
    "            val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 \n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            return val_position * size_scale\n",
    "    if 'x_order' in kwargs: \n",
    "        x_names = [t for t in kwargs['x_order']]\n",
    "    else:\n",
    "        x_names = [t for t in sorted(set([v for v in x]))]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "    if 'y_order' in kwargs: \n",
    "        y_names = [t for t in kwargs['y_order']]\n",
    "    else:\n",
    "        y_names = [t for t in sorted(set([v for v in y]))]\n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x10 grid\n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "\n",
    "    marker = kwargs.get('marker', 's')\n",
    "\n",
    "    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', \n",
    "        'y_order', 'xlabel', 'ylabel'\n",
    "    ]}\n",
    "\n",
    "    ax.scatter(\n",
    "        x=[x_to_num[v] for v in x],\n",
    "        y=[y_to_num[v] for v in y],\n",
    "        marker=marker,\n",
    "        s=[value_to_size(v) for v in size], \n",
    "        c=[value_to_color(v) for v in color],\n",
    "        **kwargs_pass_on\n",
    "    )\n",
    "    ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "    ax.set_xticklabels([k for k in x_to_num], rotation=45, horizontalalignment='right')\n",
    "    ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "    ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor')\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "\n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "\n",
    "    ax.set_xlabel(kwargs.get('xlabel', ''))\n",
    "    ax.set_ylabel(kwargs.get('ylabel', ''))\n",
    "\n",
    "    # Add color legend on the right side of the plot\n",
    "    if color_min < color_max:\n",
    "        ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n",
    "\n",
    "        col_x = [0]*len(palette) # Fixed x coordinate for the bars\n",
    "        bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n",
    "\n",
    "        bar_height = bar_y[1] - bar_y[0]\n",
    "        ax.barh(\n",
    "            y=bar_y,\n",
    "            width=[5]*len(palette), # Make bars 5 units wide\n",
    "            left=col_x, # Make bars start at 0\n",
    "            height=bar_height,\n",
    "            color=palette,\n",
    "            linewidth=0\n",
    "        )\n",
    "        ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n",
    "        ax.grid(False) # Hide grid\n",
    "        ax.set_facecolor('white') # Make background white\n",
    "        ax.set_xticks([]) # Remove horizontal ticks\n",
    "        ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n",
    "        ax.yaxis.tick_right() # Show vertical ticks on the right\n",
    "        plt.gca().spines['right'].set_color('none')\n",
    "        plt.gca().spines['top'].set_color('none')\n",
    "        plt.gca().spines['bottom'].set_color('none')\n",
    "        plt.gca().spines['left'].set_color('none')\n",
    "        \n",
    "def corrplot(data, size_scale=500, marker='s'):\n",
    "    corr = pd.melt(data.reset_index(), id_vars='index').replace(np.nan, 0)\n",
    "    corr.columns = ['x', 'y', 'value']\n",
    "    heatmap(\n",
    "        corr['x'], corr['y'],\n",
    "        color=corr['value'], color_range=[-1, 1],\n",
    "        palette=sns.diverging_palette(20, 220, n=256),\n",
    "        size=corr['value'].abs(), size_range=[0,1],\n",
    "        marker=marker,\n",
    "        x_order=data.columns,\n",
    "        y_order=data.columns[::-1],\n",
    "        size_scale=size_scale\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'corr' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a3befc56624a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"whitegrid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcorrplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corr' is not defined"
     ]
    }
   ],
   "source": [
    "## Plotting\n",
    "#df_lt.fillna(0, inplace = True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize  =(10, 10))\n",
    "corrplot(corr.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Analysis\n",
    "The scenario approach to risk management defines a number of scenarios where in each scenario various risk factors, e.g. the price of the underlying security and implied volatility, are assumed to have moved by some fixed amounts. For example, a scenario might assume that all stock prices have fallen by 10% and all implied volatilities have increased by 5 percentage points. Another scenario might assume the same movements but with an additional steepening of the volatility surface. The risk of a portfolio could then be determined by computing the P&L in each scenario and then considering the results, taking action (to reduce risk) where appropriate. This risk factors and scenario variations can be displayed through a pivot table.\n",
    "\n",
    "These assessments can be used to examine the amount of risk present within a given investment as related to a variety of potential events, ranging from highly probable to highly improbable. Depending on the result of the analysis, an investor can determine if the level of risk present falls within his comfort zone.\n",
    "\n",
    "One type of scenario analysis that looks specifically at worst-case scenarios is stress testing. These are computer simulations techniques used to test the resilience of institutions and investment portfolios against possible future financial situations. Such testing is customarily used by the financial industry to help gauge investment risk and the adequacy of assets, as well as to help evaluate internal processes and controls. In recent years, regulators have also required financial institutions to carry out stress tests to ensure their capital holdings and other assets are adequate.\n",
    "\n",
    "        - Scenario analysis is the process of estimating the expected value of a portfolio after a given change in \n",
    "        the values of key factors take place.\n",
    "        - Both likely scenarios and unlikely worst-case events can be tested in this fashion—often relying on \n",
    "        computer simulations.\n",
    "        - Scenario analysis can apply to investment strategy as well as corporate finance.\n",
    "\n",
    "There are many different ways to approach scenario analysis. A common method is to determine the standard deviation of daily or monthly security returns and then compute what value is expected for the portfolio if each security generates returns that are two or three standard deviations above and below the average return. This way, an analyst can have a reasonable amount of certainty regarding the change in the value of a portfolio during a given time period, by simulating these extremes.\n",
    "\n",
    "### Pivot Table\n",
    "A pivot table is a table of statistics that summarizes the data of a more extensive table. Pivot tables are a technique in data processing. They arrange and rearrange (or \"pivot\") statistics in order to draw attention to useful information. A pivot table can help quickly summarize the data and highlight the desired information. A pivot table usually consists of row, column and data (or fact) fields. In this case, the column is Volatility Stress, the row is Underlying and Underlying Stress and the data seen is (sum of) PnL. These fields allow several kinds of aggregations, including: sum, average, standard deviation, count, etc. In this case, the total value of PnL is displayed here using a sum aggregation.\n",
    "\n",
    "The below code shows the pivot table for all three different underlying securities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stress_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c0ca3a7ebb3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## All security pivot table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m table = pd.pivot_table(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstress_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Underlying'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Underlying Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Volatility Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PnL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     aggfunc = np.sum)\n\u001b[0;32m      5\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stress_data' is not defined"
     ]
    }
   ],
   "source": [
    "## All security pivot table\n",
    "table = pd.pivot_table(\n",
    "    stress_data, index = ['Underlying', 'Underlying Stress'], columns = ['Volatility Stress'], values = ['PnL'], \n",
    "    aggfunc = np.sum)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The S&P 500 Index\n",
    "The pivot table below shows the P&L under various scenarios of an options portfolio with the S&P 500 as the underlying security. The \n",
    "vertical axis represents percentage shifts in the price of the underlying security, i.e. the S&P 500, whereas the horizontal axis represents absolute changes in the implied volatility of each option in the portfolio. For example, we see that if the S&P 500 were to fall by 20% and implied volatilities were to all rise by 5 percentage points, then the portfolio would lose 13.892 million dollars (assuming that the numbers in pivot table are expressed in units of 1,000 dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stress_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6df91e1388f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## S&P 500 pivot table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m SP5_table = pd.pivot_table(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstress_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstress_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Underlying'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SPX Index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Underlying'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Underlying Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Volatility Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PnL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     aggfunc = np.sum)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stress_data' is not defined"
     ]
    }
   ],
   "source": [
    "## S&P 500 pivot table\n",
    "SP5_table = pd.pivot_table(\n",
    "    stress_data[stress_data['Underlying'] == 'SPX Index'], index = ['Underlying', 'Underlying Stress'], \n",
    "    columns = ['Volatility Stress'], values = ['PnL'], \n",
    "    aggfunc = np.sum)\n",
    "SP5_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta-Vega-Gamma Approximations and Scenario Analysis II\n",
    "This section contains a piece of code to display the sum of the ‘Total \\\\$Delta’ (column V) grouped by the underlying security. Since there are just three underlying securities, the codes outputs three ‘Total \\\\$Delta’s: one for each underlying. Each of these “Total \\\\$Delta”s are denominated in different currencies and it wouldn’t make sense to add them together without first converting them all to a common currency. The currency used will be USD. This process will be repeated for Total \\\\$Gamma and Total Vega 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'OptionsData.csv' does not exist: b'OptionsData.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c839b00fc812>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Import data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'OptionsData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'OptionsData.csv' does not exist: b'OptionsData.csv'"
     ]
    }
   ],
   "source": [
    "## Import data\n",
    "data = pd.read_csv('OptionsData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-964a53db8301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Dataframe info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moptions_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The dataset has {options_data.shape[0]} rows and {options_data.shape[1]} columns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptions_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "## Dataframe info\n",
    "options_data = data.copy()\n",
    "print(f'The dataset has {options_data.shape[0]} rows and {options_data.shape[1]} columns')\n",
    "options_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ecf23caa9f72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Format options_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mformat_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Format options_data\n",
    "format_df(options_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2763302a4a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m print(f\"The three underlying securities are the {options_data['Underlying'].unique()[0]},\" \n\u001b[0m\u001b[0;32m      2\u001b[0m       f\"the {options_data['Underlying'].unique()[1]} and the {options_data['Underlying'].unique()[2]}\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"The three underlying securities are the {options_data['Underlying'].unique()[0]},\" \n",
    "      f\"the {options_data['Underlying'].unique()[1]} and the {options_data['Underlying'].unique()[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Index\n",
    "A market index is a hypothetical portfolio of investment holdings which represents a segment of the financial market. The calculation of the index value comes from the prices of the underlying holdings. Some indices have values based on market-cap weighting, revenue weighting, float-weighting and fundamental-weighting. Weighting is a method of adjusting the individual impact of items in an index.\n",
    "\n",
    "An investor can't invest directly in an market index, so these indicators as portfolios are used broadly as benchmarks. Each index has its own methodology which is calculated and maintained by the index provider. Indexes are deeply entrenched in the investment management business with funds using them as benchmarks for performance comparisons and managers using them as the basis for creating investable index funds.\n",
    "\n",
    "        - Market indexes provide a broad representative portfolio of investment holdings.\n",
    "        - Methodologies for constructing individual indexes vary but nearly all calculations are based on \n",
    "        weighted average mathematics.\n",
    "        - Indexes are used as benchmarks to gauge the movement and performance of market segments.\n",
    "        - Investors use indexes as a basis for portfolio or passive index investing.\n",
    "\n",
    "As a hypothetical portfolio of holdings, indexes act as a benchmark comparisons for a variety of purposes across the financial markets. The Dow Jones Industrial Average, S&P 500 and Nasdaq Composite are three popular U.S. indices. These three indexes include the 30 largest stocks in the U.S. by market cap, the 500 largest stocks and all of the stocks on the Nasdaq exchange, respectively. Since they include some of the most significant U.S. stocks, these benchmarks can be a good representation of the overall U.S. stock market. This project observers the SPX Index, the SX5E Index and the NKY Index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 Index\n",
    "The S&P 500 measures the stock performance of 500 large companies listed on stock exchanges in the United States. The average annual total return of the index, including dividends, since inception in 1926 has been 9.8%; with several years where the index declined over 30%. The index has posted annual increases 70% of the time. Its market cap was US$28.1 trillion as of early 2020.\n",
    "\n",
    "The components of the S&P 500 are selected by a committee. When considering the eligibility of a new addition, the committee assesses the company's merit using eight primary criteria: market capitalization, liquidity, domicile, public float, sector classification, financial viability, and length of time publicly traded and stock exchanged. \n",
    "\n",
    " order to be added to the index, a company must satisfy the following liquidity-based size requirements:\n",
    "\n",
    "    1. Market capitalization must be greater than or equal to US$8.2 billion\n",
    "    2. Annual dollar value traded to float-adjusted market capitalization is greater than 1.0\n",
    "    3. Minimum monthly trading volume of 250,000 shares in each of the six months leading up to the evaluation date\n",
    "\n",
    "The committee selects the companies in the S&P 500 so they are representative of the industries in the Economy of the United States.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SX5E Index\n",
    "The EURO STOXX 50 is a stock index of Eurozone stocks designed by STOXX, an index provider owned by the  Deutsche Börse Group. The goal, according to STOXX, is \"to provide a blue-chip representation of Supersector leaders in the Eurozone.\" It is made up of fifty of the largest and most liquid stocks. Its market cap as of mid 2020 is just under EUR2 trillion.\n",
    "\n",
    "The index covers 50 stocks from 8 Eurozone countries: Belgium, Finland, France, Germany, Ireland, Italy, Luxembourg, the Netherlands and Spain. The EURO STOXX 50 Index is licensed to financial institutions to serve as an underlying for a wide range of investment products such as exchange-traded funds (ETFs), futures, options and structured products worldwide.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NKY Index\n",
    "The Nikkei 225 is a stock market index of the Tokyo Stock Exchange (TSE). It has been calculated daily by the Nihon Keizai Shinbun (The Nikkei) newspaper since 1950. t is a price-weighted index, operating in the Japanese Yen (JP¥), and its components are reviewed once a year. The Nikkei measures the performance of 225 large, publicly owned companies in Japan from a wide array of industry sectors. Its market cap as of early 2019 was US$5.67 trillion.\n",
    "\n",
    "It is a price-weighted index, operating in the Japanese Yen (JP¥), and its components are reviewed once a year. There is concern that the rise since 2013 is artificial and due to purchases by the Bank of Japan (\"BOJ\"). From a start in 2013, by end 2017, The BOJ owned circa 75% of all Japanese Exchange Traded Funds (\"ETFs\"), and are a top 10 shareholder of 90% of the Nikkei 225 constituents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total \\\\$Delta\n",
    "This section converts different currencies into USD and proceeds to sum the Total \\\\$Delta for each underlying security\n",
    "\n",
    "#### Delta $(\\Delta)$\n",
    "Delta represents the rate of change between the option's price and a \\\\$1 change in the underlying asset's price. In other words, the price sensitivity of the option relative to the underlying. If an investor is long a call option with a delta of 0.50. Therefore, if the underlying stock increases by \\\\$1, the option's price would theoretically increase by 50 cents. \n",
    "\n",
    "The (absolute value of) Delta is close to, but not identical with, the percent moneyness of an option, i.e., the implied probability that the option will expire in-the-money (if the market moves under Brownian motion in the risk-neutral measure).\n",
    "\n",
    "For option traders, delta also represents the hedge ratio for creating delta-neutral position. If an investor purchases a standard American call option with a 0.40 delta, the investor will need to sell 40 shares of stock to be fully hedged. Net delta for a portfolio of options can also be used to obtain the portfolio's hedge ration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to return underlying column sum\n",
    "def underlying_sum(column):\n",
    "    return options_data.groupby('Underlying')[column].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the total deltas for each underlying security but in this sumation each underlying security is expressed in a different currency. \n",
    "\n",
    "        NKY Index (Japan) is expressed in Japanese Yen\n",
    "        SPX Index (U.S) is expressed in US Dollars\n",
    "        SX5E Index (Europe) is expressed in Euros\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-266ce3304279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munderlying_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total $Delta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-4ecf164830b2>\u001b[0m in \u001b[0;36munderlying_sum\u001b[1;34m(column)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Function to return underlying column sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0munderlying_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moptions_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Underlying'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "underlying_sum('Total $Delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step in this process is to ensure that all monetary figures are expressed in the same currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forex_python.converter import CurrencyRates\n",
    "c = CurrencyRates()\n",
    "\n",
    "def currency_converter(currency, value_column):\n",
    "    df = options_data[options_data['Currency'] == currency]\n",
    "    df_l = df[value_column].tolist()\n",
    "    df_l = [round(c.convert(currency, 'USD', x)) for x in df_l]\n",
    "    return df_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ea9a2466b90e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0musd_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Total $Delta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0meur_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EUR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Total $Delta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mjpy_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JPY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Total $Delta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-f310f68818b9>\u001b[0m in \u001b[0;36mcurrency_converter\u001b[1;34m(currency, value_column)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Currency'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcurrency\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_l\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "usd_l = currency_converter('USD', 'Total $Delta')\n",
    "eur_l = currency_converter('EUR', 'Total $Delta')\n",
    "jpy_l = currency_converter('JPY', 'Total $Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'usd_l' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-01a384332cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0musd_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musd_l\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meur_l\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mjpy_l\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'usd_l' is not defined"
     ]
    }
   ],
   "source": [
    "usd_all = usd_l + eur_l + jpy_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'usd_all' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bc3844a5e2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'USD Total $Delta'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musd_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'usd_all' is not defined"
     ]
    }
   ],
   "source": [
    "options_data['USD Total $Delta'] = usd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Delta values are now all in the same currency, US Dollars, the grouping and aggregation can now continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1044027b3df7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munderlying_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'USD Total $Delta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-4ecf164830b2>\u001b[0m in \u001b[0;36munderlying_sum\u001b[1;34m(column)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Function to return underlying column sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0munderlying_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moptions_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Underlying'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "underlying_sum('USD Total $Delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the process is to be repeated various times for different columns, a function is coded to faciliate the repetition of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underlying_security_sum(value_column, new_df_column):\n",
    "\n",
    "    usd_l = currency_converter('USD', value_column)\n",
    "    eur_l = currency_converter('EUR', value_column)\n",
    "    jpy_l = currency_converter('JPY', value_column)\n",
    "    usd_all = usd_l + eur_l + jpy_l\n",
    "    options_data[new_df_column] = usd_all\n",
    "\n",
    "    return underlying_sum(new_df_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Gamma\n",
    "This section replicates the process above which converts different currencies into USD and proceeds to sum the Total \\\\$Gamma for each underlying security.\n",
    "\n",
    "#### Gamma $(\\Gamma)$\n",
    "Gamma represents the rate of change between an option's delta and the underlying asset's price. This is called second-order (second-derivative) price sensitivity. Gamma indicates the amount the delta would change given a \\\\$1 move in the underlying security. If an investor is long one call option on hypothetical stock XYZ. The call option has a delta of 0.50 and a gamma of 0.10. Therefore, if stock XYZ increases or decreases by \\\\$1, the call option's delta would increase or decrease by 0.10.\n",
    "\n",
    "Gamma is greatest approximately at-the-money (ATM) and diminishes the further out you go either in-the-money (ITM) or out-of-the-money (OTM). Gamma is important because it corrects for the convexity of value. \n",
    "\n",
    "Options traders may opt to not only hedge delta but also gamma in order to be delta-gamma neutral, meaning that as the underlying price moves, the delta will remain close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-23ab9c7fb0f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munderlying_security_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total $Gamma'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'USD Total $Gamma'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-0840ed9dd1f6>\u001b[0m in \u001b[0;36munderlying_security_sum\u001b[1;34m(value_column, new_df_column)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0munderlying_security_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_df_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0musd_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0meur_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EUR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mjpy_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JPY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-f310f68818b9>\u001b[0m in \u001b[0;36mcurrency_converter\u001b[1;34m(currency, value_column)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Currency'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcurrency\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_l\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "underlying_security_sum('Total $Gamma', 'USD Total $Gamma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Vega 1%\n",
    "This section replicates the process above which converts different currencies into USD and proceeds to sum the Total Vega 1% for each underlying security.\n",
    "\n",
    "#### Vega $(V)$\n",
    "Vega represents the rate of change between an option's value and the underlying asset's implied volatility/ This is the option's sensitivity to volatility. Vega indicates the amount an option's price changes given a 1% change in implied volatility. An option with a Vega of 0.10 indicates the option's value is expected to change by 20 cents if the implied volatility changed by 1%\n",
    "\n",
    "Vega can be an important Greek to monitor for an option trader, especially in volatile markets, since the value of some option strategies can be particularly sensitive to changes in volatility. \n",
    "\n",
    "Because increased volatility implies that the underlying instrument is more likely to experience extreme values, a rise in volatility will correspondingly increase the value of an option. Conversely, a decrease in volatility will negatively affect the value of the option. Vega is at its maximum for at-the-money options that have longer times until expiration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'options_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9d44f3d4fd58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munderlying_security_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total Vega 1%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'USD Total Vega 1%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-0840ed9dd1f6>\u001b[0m in \u001b[0;36munderlying_security_sum\u001b[1;34m(value_column, new_df_column)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0munderlying_security_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_df_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0musd_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0meur_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EUR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mjpy_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JPY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-f310f68818b9>\u001b[0m in \u001b[0;36mcurrency_converter\u001b[1;34m(currency, value_column)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrency_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptions_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Currency'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcurrency\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_l\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options_data' is not defined"
     ]
    }
   ],
   "source": [
    "underlying_security_sum('Total Vega 1%', 'USD Total Vega 1%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing P&L to Pivot-Table P&L D-G-V Approximation\n",
    "Using the dollar values of each variable we can approximate the P&L to changes in both the underlying’s price and volatility. The formula used for the approximations are:\n",
    "\n",
    "$$PnL = \\delta S(\\frac{\\Delta S}{S})+\\frac{\\Gamma S^2}{2} * (\\frac{\\Delta S}{S})^2 + vega \\Delta \\sigma$$\n",
    "\n",
    "The Delta-Gamma-Vega Approximation is very accurate estimating the P&L for small changes. The higher the change, the worse is the approximation. The results are therefore consistent with what is expected given the pivot table found above, as the approximation in general only holds for small changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation and Construction of Actual, Estimated and True Efficient Frontiers\n",
    "The purpose of this section is to explore the effect of estimation error on the computation of efficient portfolios by comparing the “true”, “estimated”, and “actual” efficient frontiers. To that end, the expected return and covariance matrix imported from .csv are the “true” values for the expected returns and covariances for a set of eight assets. These are monthly expected returns and covariances. This section will introduce essential terminology tied into mean-variance optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'covariance_matrix.csv' does not exist: b'covariance_matrix.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b1045a8c014f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Read the cov_matrix data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'covariance_matrix.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcov_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Asset Class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'covariance_matrix.csv' does not exist: b'covariance_matrix.csv'"
     ]
    }
   ],
   "source": [
    "## Read the cov_matrix data\n",
    "data = pd.read_csv('covariance_matrix.csv')\n",
    "cov_mtx = data.copy()\n",
    "cov_mtx.set_index('Asset Class', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cov_mtx' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-963eef2c54e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cov_mtx' is not defined"
     ]
    }
   ],
   "source": [
    "## Covariance matrix\n",
    "cov_mtx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cov_mtx' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-38024323a701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cov_mtx' is not defined"
     ]
    }
   ],
   "source": [
    "## Numpy array\n",
    "cov = cov_mtx.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'expected_returns.csv' does not exist: b'expected_returns.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-425f0185dc50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Read the expected returns data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'expected_returns.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mexp_rtns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Asset class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'expected_returns.csv' does not exist: b'expected_returns.csv'"
     ]
    }
   ],
   "source": [
    "## Read the expected returns data\n",
    "data = pd.read_csv('expected_returns.csv')\n",
    "exp_rtns = data.copy()\n",
    "exp_rtns.set_index('Asset class', inplace = True)\n",
    "exp_rtns.replace('%', '', regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'exp_rtns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d487873a06eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Change datatype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Expected Return (%)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Expected Return (%)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Standard Dev (%)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Standard Dev (%)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_rtns' is not defined"
     ]
    }
   ],
   "source": [
    "## Change datatype\n",
    "exp_rtns['Expected Return (%)'] = exp_rtns['Expected Return (%)'].astype(float)\n",
    "exp_rtns['Standard Dev (%)'] = exp_rtns['Standard Dev (%)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'exp_rtns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5db93f352e75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Expected returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_rtns' is not defined"
     ]
    }
   ],
   "source": [
    "## Expected returns\n",
    "exp_rtns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'exp_rtns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1e226dba7df9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_rtns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Expected Return (%)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_rtns' is not defined"
     ]
    }
   ],
   "source": [
    "## Numpy array\n",
    "mean = exp_rtns['Expected Return (%)'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating 5 Years of Monthly Returns with multivariate_normal\n",
    "The numpy.random.multivariate_normal draws random samples from a multivariate normal distribution.\n",
    "\n",
    "The multivariate normal, multinormal or Gaussian distribution is a generalization of the one-dimensional normal distribution to higher dimensions. Such a distribution is specified by its mean and covariance matrix. These parameters are analogous to the mean (average or “center”) and variance (standard deviation, or “width,” squared) of the one-dimensional normal distribution.\n",
    "\n",
    "The mean is a coordinate in N-dimensional space, which represents the location where samples are most likely to be generated. This is analogous to the peak of the bell curve for the one-dimensional or univariate normal distribution.\n",
    "\n",
    "Covariance indicates the level to which two variables vary together. From the multivariate normal distribution, we draw N-dimensional samples, $X = [x_1, x_2, ... x_N]$. The covariance matrix element $C_{ij}$ is the covariance of $x_i$ and $x_j$. The element $C_{ii}$ is the variance of $x_i$ (i.e. its “spread”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-0357a07741dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## multivariate normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmonthly_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "## multivariate normal\n",
    "monthly_returns = np.random.multivariate_normal(mean, cov_mtx, size = 60).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'monthly_returns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-bdffedecdd0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Sample mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmonthly_returns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'monthly_returns' is not defined"
     ]
    }
   ],
   "source": [
    "## Sample mean\n",
    "sample_mean = monthly_returns.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Matrix\n",
    "A covariance matrix (or variance-covariance matrix) is a square matrix is a square matrix giving the covariance between each pair of elements of a given random vector. Intuitively, the covariance matrix generalises the notion of variance to multiple dimensions. \n",
    "\n",
    "Covariance is a measure of the joint variability of two random variables. If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, the covariance is positive. In the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, the covariance is negative. The sign of the covariance therefore shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret because it is **not normalized** and hence depends on the magnitudes of the variables. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation.\n",
    "\n",
    "A covariance matrix is a $nxn$ symmetric matrix where $n$ is the number of columns of the matrix you are starting with and shows how the vector variables **covariate**, meaning how they tend to move in relation to one another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'monthly_returns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-158f0df80a8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Sample Covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_cov_rtns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonthly_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msample_cov_rtns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_cov_rtns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample_cov_rtns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msample_cov_rtns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'monthly_returns' is not defined"
     ]
    }
   ],
   "source": [
    "## Sample Covariance matrix\n",
    "sample_cov_rtns = np.cov(monthly_returns)\n",
    "sample_cov_rtns = pd.DataFrame(sample_cov_rtns)\n",
    "sample_cov_rtns.columns = cov_mtx.columns\n",
    "sample_cov_rtns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the main diagonal the variance of each vector and on all other coordinates the covariance is found since $Var(X) = cov(X, X)$\n",
    "\n",
    "In the main diagonal no values can be negative since they represent the variance of a vector. On any other position,\n",
    "the covariance can be obtained as a product of two standard deviations (that are always non negative) ($s(x)$ and $s(Y)$) and the Pearsons correlation coefficient $p$ that instead varies between $[-1, 1]$: this is what makes the coefficient that makes the values positive or negative. \n",
    "\n",
    "$$cov(X, Y) = p(X, y)s(X)s(Y)$$\n",
    "\n",
    "There are three possibilities:\n",
    "\n",
    "1. $p(X, Y) == 0$: No correlation between vectors\n",
    "2. $p(X, Y) > 0$: Positive correlation, meaning that when the vector $X$ grows so does the magnitude of $Y$.\n",
    "3. $p(X, Y) < 0$: Negative correlation, meaning that when the vector $X$ grows, the magnitude of $Y$ decreases.\n",
    "\n",
    "The standard deviations effect on the coefficients in the matrices is \"just\" magnitude, meaning they highlight more correlation when the standard deviation of the data points is higher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sample_cov_rtns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-0832f2dfbfa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Create triangle df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_cov_rtns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_lt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_cov_rtns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_cov_rtns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_lt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_cov_rtns' is not defined"
     ]
    }
   ],
   "source": [
    "## Create triangle df\n",
    "np.tril(np.ones(sample_cov_rtns.shape)).astype(np.bool)[:, :]\n",
    "df_lt = sample_cov_rtns.where(np.tril(np.ones(sample_cov_rtns.shape)).astype(np.bool))\n",
    "df_lt.columns = cov_mtx.columns\n",
    "\n",
    "## Plot\n",
    "sns.set_style(style='white')\n",
    "plt.figure(figsize = (8, 8))\n",
    "ax = sns.heatmap(df_lt, cmap = sns.diverging_palette(20, 220, n = 200), square = True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\n",
    "ax.set_yticklabels(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\n",
    "plt.title('Covariance Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected (Realized) Efficient Frontier\n",
    "The efficient frontier is the set of optimal portfolios that offer the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. Portfolios that lie below the efficient frontier are sub-optimal because they do not provide enough return for the level of risk. Portfolios that cluster to the right of the efficient frontier are sub-optimal because the have a higher level of risk for the defined rate of return. Formally, the frontier is the set of portfolios which satisfy the condition that no other portfolio exists with a higher expected return but with the same standard deviation of return (i.e., the risk).\n",
    "\n",
    "The efficient frontier theory was introduced by Nobel Laureate Harry Markowitz in 1952 and is a cornerstone of modern portfolio theory (MPT)\n",
    "\n",
    "### Modern Portfolio Theory\n",
    "Modern portfolio theory is a theory on how risk-averse investors can construct portfolios to optimize or maximize expected return based on a given level of market risk, emphasizing that risk is an inherent part of higher reward. MPT argues that an investments risk and return characteristics should not be viewed alone, but should be evaluated by how the investment affects the overall portfolio's risk and return.\n",
    "\n",
    "Based on statistical measures such as variance and correlation, and individual investment's return is less important than how the investment behaves in the context of the entire portfolio. MPT makes the assumption that investors are risk-averse, meaning they prefer a less risky portfolio to a riskier one for a given level of return. Ultimately implying that an investor will take on more risk only if they can expect more reward.\n",
    "\n",
    "The expected return of the portfolio is calculated as a weighted sum of the individual assets' returns. \n",
    "\n",
    "$$ E(R_p) = \\sum_{i} w_i E (R_i) $$\n",
    "\n",
    "Where $R_p$ is the return on the portfolio, $R_i$ is the return on asset $i$ and $w_i$ is the weighting of the component asset $i$ (the proportion of asset $i$ in the portfolio).\n",
    "\n",
    "The portfolio's risk is a complicated function of the variances of each asset and the correlations of each pair of assets. To calculate the risk of a four asset portfolio, an investor needs each of the four assets' variances and six correlation values, since there are six possible two-asset combinations with four assets. Because of the assert correlations, the total portfolio risk, or standard deviation, is lower than what would be calculated by a weighted sum.\n",
    "\n",
    "$$ \\sigma_p^2 = \\sum_{i} w_i^2 \\sigma_i^2 + \\sum_i \\sum_\\neq w_i w_j \\sigma_i \\sigma_j \\rho_{ij}$$\n",
    "\n",
    "Where $\\sigma$ is the sample (standard deviation) of the periodic returns on an asset, and $\\rho_ij$ is the correlation coefficient between the returns on assets $i$ and $j$. \n",
    "\n",
    "Portfolio return volatility (standard deviation) is the square root of the variance.\n",
    "\n",
    "$$\\sigma_p = \\sqrt{\\sigma_p^2}$$\n",
    "\n",
    "### Diversification\n",
    "An investor can reduce portfolio risk simply by holding combinations of instruments not perfectly positively correlated $(-1 \\leq \\rho_{ij} \\leq 1)$. By holding diversified portfolio assets investors can reduce their exposure to individual asset risk. Diversification may allow for the same portfolio expected return with reduced risk. \n",
    "\n",
    "If all the asset pairs have correlations of 0—they are perfectly uncorrelated—the portfolio's return variance is the sum over all assets of the square of the fraction held in the asset times the asset's return variance. If all the asset pairs have correlations of 1—they are perfectly positively correlated—then the portfolio return’s standard deviation is the sum of the asset returns’ standard deviations weighted by the fractions held in the portfolio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cov_mtx' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9bf09f6dada0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_assets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_portfolios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mselected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cov_mtx' is not defined"
     ]
    }
   ],
   "source": [
    "# set the number of combinations for imaginary portfolios\n",
    "num_assets = 8\n",
    "num_portfolios = 10000\n",
    "selected = cov_mtx.columns \n",
    "\n",
    "np.random.seed(11)\n",
    "port_returns = []\n",
    "port_volatility = []\n",
    "sharpe_ratio = []\n",
    "stock_weights = []\n",
    "\n",
    "# populate the empty lists with each portfolios returns,risk and weights\n",
    "for single_portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    returns = np.dot(weights, mean)\n",
    "    volatility = np.sqrt(np.dot(weights.T, np.dot(cov, weights)))\n",
    "    sharpe = returns / volatility\n",
    "    sharpe_ratio.append(sharpe)\n",
    "    port_returns.append(returns)\n",
    "    port_volatility.append(volatility)\n",
    "    stock_weights.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'port_returns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3162bdd3d38a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## a dictionary for Returns and Risk values of each portfolio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m portfolio = {'Returns': port_returns,\n\u001b[0m\u001b[0;32m      3\u001b[0m              \u001b[1;34m'Volatility'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mport_volatility\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m              'Sharpe Ratio': sharpe_ratio}\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'port_returns' is not defined"
     ]
    }
   ],
   "source": [
    "## a dictionary for Returns and Risk values of each portfolio\n",
    "portfolio = {'Returns': port_returns,\n",
    "             'Volatility': port_volatility,\n",
    "             'Sharpe Ratio': sharpe_ratio}\n",
    "\n",
    "## extend original dictionary to accomodate each ticker and weight in the portfolio\n",
    "for counter,symbol in enumerate(selected):\n",
    "    portfolio[symbol+' Weight'] = [Weight[counter] for Weight in stock_weights]\n",
    "\n",
    "## make a nice dataframe of the extended dictionary\n",
    "df = pd.DataFrame(portfolio)\n",
    "\n",
    "## get better labels for desired arrangement of columns\n",
    "column_order = ['Returns', 'Volatility', 'Sharpe Ratio'] + [stock +' Weight' for stock in selected]\n",
    "\n",
    "## reorder dataframe columns\n",
    "df = df[column_order]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe Ratio\n",
    "The Sharpe ratio was developed by Nobel laureate William F. Sharpe and is used to help investors understand the return of an investment compared to its risk. The ratio measures the performance of an investment compared to a risk-free asset, after adjusting for risk. It is defined as the difference between the returns on the investment and the risk-free return, divided by the standard deviation (volatility) of the investment. It represents the additional amount of return that an investor receives per unit of increase in risk.\n",
    "\n",
    "The ex-post Sharpe Ratio is calculated as follows:\n",
    "\n",
    "$$ Sharpe Ratio = \\frac{(R_p - R_f)}{\\sigma_p} $$\n",
    "\n",
    "$R_p$ is the return on the portfolio\n",
    "$R_f$ is the risk-free rate\n",
    "$\\sigma_p$ is the standard deviation of the portfolio's excess return\n",
    "\n",
    "The Sharpe ratio can be used to evaluate a portfolio's past performance (ex-post) where actual returns are used in the formula. It can also help explain whether a portfolio's excess returns are due to smart investment decisions or a result of too much risk. The greater a portfolio's Sharpe ratio, the better its risk-adjusted-performance. If the analysis results in a negative Sharpe ratio, it either means the risk-free rate is greater than the portfolio’s return, or the portfolio's return is expected to be negative. In either case, a negative Sharpe ratio does not convey any useful meaning.\n",
    "\n",
    "        - The Sharpe ratio adjusts a portfolio’s past performance—or expected future performance—for the excess \n",
    "        risk that was taken by the investor.\n",
    "        - A high Sharpe ratio is good when compared to similar portfolios or funds with lower returns.\n",
    "        - The Sharpe ratio has several weaknesses, including an assumption that investment returns are normally distributed.\n",
    "\n",
    "The portfolios created above can be visualised along with their respective Sharpe ratio in order to see the respective returns and volatility each portfolio holds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e473a50c7c06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volatility'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Returns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sharpe Ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'coolwarm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshrink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrawedges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# plot frontier, max sharpe & min Volatility values with a scatterplot\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.style.use('seaborn-white')\n",
    "plt.scatter(x = df['Volatility'], y = df['Returns'], c=  df['Sharpe Ratio'], cmap = 'coolwarm')\n",
    "cb = plt.colorbar(shrink = 0.8, drawedges = False)\n",
    "cb.outline.set_visible(False)\n",
    "plt.xlabel('Volatility (Std. Deviation)')\n",
    "plt.ylabel('Expected Returns')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum Variance Portfolio\n",
    "A minimum variance portfolio (MVP) is a collection of securities that combine to minimize the price volatility of the overall portfolio. To build a minimum variance portfolio, you need to stick with low-volatility investments or a combination of volatile investments with low correlation to each other. In practice, the MVP can only be determined historically (ex post) for a specific sample and return frequency. This means different low volatility portfolios (LVP) co-exist, all aiming to reduce and minimize future volatility (ex ante).\n",
    "\n",
    "#### Maximum Sharpe Portfolio\n",
    "The Sharpe ratio measures the performance of an investment compared to a risk-free asset, after adjusting to its risk. Maximum Sharpe Portfolio or Tangency Portfolio is a portfolio on the efficient frontier at the point where line drawn from the point (0, risk-free rate) is tangent to the efficient frontier.\n",
    "\n",
    "#### Maximum Return Portfolio\n",
    "A maximum return portfolio is a collection of securities that combine to maximize the price return of the overall portfolio. This portfolio is built with high-risk investments that will (usually) have high volatility. This portfolio is for risk-seeking investors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c42fdda3afc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## find min volatility, max sharpe and max return values in the dataframe (df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmin_volatility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volatility'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmax_sharpe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sharpe Ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmax_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Returns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## find min volatility, max sharpe and max return values in the dataframe (df)\n",
    "min_volatility = df['Volatility'].min()\n",
    "max_sharpe = df['Sharpe Ratio'].max()\n",
    "max_return = df['Returns'].max()\n",
    "\n",
    "## use the min, max values to locate and create the two special portfolios\n",
    "sharpe_portfolio = df.loc[df['Sharpe Ratio'] == max_sharpe]\n",
    "min_variance_port = df.loc[df['Volatility'] == min_volatility]\n",
    "max_return_port = df.loc[df['Returns'] == max_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c2c4603c584b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volatility'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Returns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sharpe Ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'coolwarm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshrink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrawedges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## plot frontier, max sharpe & min Volatility values with a scatterplot\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.style.use('seaborn-white')\n",
    "plt.scatter(x = df['Volatility'], y = df['Returns'], c=  df['Sharpe Ratio'], cmap = 'coolwarm')\n",
    "cb = plt.colorbar(shrink = 0.8, drawedges = False)\n",
    "cb.outline.set_visible(False)\n",
    "plt.scatter(\n",
    "    x = sharpe_portfolio['Volatility'], y = sharpe_portfolio['Returns'], c = '#a6cee3', \n",
    "    marker = '+', s = 400, label = 'Max Sharpe' )\n",
    "plt.scatter(\n",
    "    x = min_variance_port['Volatility'], y = min_variance_port['Returns'], c = '#b2df8a', \n",
    "    marker = '+', s = 400, label = 'Min Variance' )\n",
    "plt.scatter(\n",
    "    x = max_return_port['Volatility'], y = max_return_port['Returns'], c = '#fb9a99', \n",
    "    marker = '+', s = 400, label = 'Max Return' )\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient Frontier with no Risk-Free Asset\n",
    "Every possible combination of risky assets, can be plotted in the risk-expected return space (visualised above: expected return (vertical) versus standard deviation). This is called the 'risk-expected return space'. The left boundary of this region is parabolic and the upper part of the parabolic boundary is the **efficient frontier** in the absence of a risk free asset. Combinations along this upper edge represent portfolios (including no holdings of the risk-free asset) for which there is lowest risk for a given level of expected return. Equivalently, a portfolio lying on the efficient frontier represents the combination offering the best possible expected return for given risk level. The tangent to the upper part of the parabolic boundary is the capital allocation line (CAL).\n",
    "\n",
    "In order to calculate the efficient frontier an optimisation problem must be constructed. Matrices are preferred calculations for the efficient frontier. In matrix form, for a given \"risk tolerance\" $q \\in [0, \\inf)$, the efficient frontier is found by minimizing the following expression:\n",
    "\n",
    "$$ w^T \\sum w - q * R^T w $$\n",
    "\n",
    "$w$ is a vector of portfolio weights and $\\sum_i w_i = 1$ (The weights can be negative, meaning investors can short a security);\n",
    "$\\sum$ is the covariance matrix for the returns of the asset in the portfolio;\n",
    "$q \\geq 0$ is a \"risk tolerance\" factor, where 0 results in the portfolio with minimal risk and $\\inf$ results in the portfolio infinitely far out on the frontier with both expected return and risk unbounded;\n",
    "$R$ is a vector of expected returns;\n",
    "$w^T \\sum w$ is the variance of the portfolio;\n",
    "$R^T w$ is the expected return on the portfolio.\n",
    "\n",
    "The above optimization problem finds the point at which the inverse of the slope of the frontier would be $q$ if portfolio return variance instead of standard deviation were plotted horizontally. The frontier in its entirety is parametric on $q$.\n",
    "\n",
    "An alternate approach to specifying the efficient frontier is to do so parametrically on the expected portfolio return $R^T w$. This version of the problem requires the minimisation of \n",
    "\n",
    "$$ w^T \\sum w $$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$ R^T w = \\mu $$\n",
    "\n",
    "The section below uses the cvxopt package to find the optimal portfolio weightings. CVXOPT is a free software package for convex optimization based on the Python programming language. Its main purpose is to make the development of software for convex optimization applications straightforward by building on Python’s extensive standard library and on the strengths of Python as a high-level programming language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "\n",
    "def optimal_portfolio(returns):\n",
    "    n = len(returns)\n",
    "    returns = np.asmatrix(returns)\n",
    "    \n",
    "    N = 100\n",
    "    mus = [10**(5.0 * t/N - 1.0) for t in range(N)]\n",
    "    \n",
    "    # Convert to cvxopt matrices\n",
    "    S = opt.matrix(np.cov(returns))\n",
    "    pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "    \n",
    "    # Create constraint matrices\n",
    "    G = -opt.matrix(np.eye(n))   # negative n x n identity matrix\n",
    "    h = opt.matrix(0.0, (n ,1))\n",
    "    A = opt.matrix(1.0, (1, n))\n",
    "    b = opt.matrix(1.0)\n",
    "    \n",
    "    # Calculate efficient frontier weights using quadratic programming\n",
    "    portfolios = [solvers.qp(mu*S, -pbar, G, h, A, b)['x'] \n",
    "                  for mu in mus]\n",
    "    \n",
    "    ## Calculate risks and returns for frontier\n",
    "    returns = [blas.dot(pbar, x) for x in portfolios]\n",
    "    risks = [np.sqrt(blas.dot(x, S*x)) for x in portfolios]\n",
    "\n",
    "    ## Calculate the 2nd degree polynomial of the frontier curve\n",
    "    m1 = np.polyfit(returns, risks, 2)\n",
    "    x1 = np.sqrt(m1[2] / m1[0])\n",
    "    \n",
    "    ## Calculate the optimal portfolio\n",
    "    wt = solvers.qp(opt.matrix(x1 * S), -pbar, G, h, A, b)['x']\n",
    "    return np.asarray(wt), returns, risks, portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'monthly_returns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-665360a12245>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimated_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimated_risks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mportfolios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimal_portfolio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonthly_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'monthly_returns' is not defined"
     ]
    }
   ],
   "source": [
    "weights, estimated_returns, estimated_risks, portfolios = optimal_portfolio(monthly_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'estimated_risks' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-b676cefcc493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Return (Mean)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Risk (Standard Deviation)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimated_risks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimated_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y-o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Estimated Efficient Frontier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'right'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'estimated_risks' is not defined"
     ]
    }
   ],
   "source": [
    "## Plotting Estimated Frontier\n",
    "fig = plt.figure(figsize = (14, 10))\n",
    "plt.ylabel('Return (Mean)')\n",
    "plt.xlabel('Risk (Standard Deviation)')\n",
    "plt.plot(estimated_risks, estimated_returns, 'y-o', color = 'black')\n",
    "plt.title('Estimated Efficient Frontier')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Frontier\n",
    "Next, lets compute the actual expected returns and standard deviations for the portfolios that were found in in the realised (estimated) frontier above. Using the W’s from the optimal sample portfolios, the expected return can be estimated and variance of each portfolio using the true returns and true variances found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'weights.csv' does not exist: b'weights.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-26f79cfb0c95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Import weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'weights.csv' does not exist: b'weights.csv'"
     ]
    }
   ],
   "source": [
    "## Import weights\n",
    "weights = pd.read_csv('weights.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-1ca0f56e55b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrisk_data_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mrisk_data_actual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mcov_mtx\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mret_data_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "## Calculate actual data\n",
    "risk_data_actual = [0] * 100\n",
    "for i in range(100):\n",
    "    risk_data_actual[i] = np.sqrt(np.asmatrix(weights)[i] @ cov_mtx @ np.asmatrix(weights)[i].transpose())\n",
    "\n",
    "ret_data_actual = weights @ mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cov_mtx' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-e51bb4379480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Diagonal elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cov_mtx' is not defined"
     ]
    }
   ],
   "source": [
    "## Diagonal elements\n",
    "cov_mtx.to_numpy().diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ret_data_actual' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a3b5942fe75b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Plotting actual frontier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrisk_data_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret_data_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y-o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#e31a1c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#fb9a99'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Actual Portfolios'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'upper left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ret_data_actual' is not defined"
     ]
    }
   ],
   "source": [
    "## Plotting actual frontier\n",
    "fig = plt.figure(figsize = (14, 10))\n",
    "plt.plot(risk_data_actual, ret_data_actual, 'y-o', color = '#e31a1c')\n",
    "plt.scatter(np.sqrt(cov_mtx.to_numpy().diagonal()), mean, color = '#fb9a99', label = 'Actual Portfolios')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.title('Actual Efficient Frontier')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.ylabel('Return (Mean)')\n",
    "plt.xlabel('Risk (Standard Deviation)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Frontier\n",
    "The true frontier is calculated using the same methodology that was used to find the estimated frontier but using the true returns and true covariance as inputs for the optimal function. Once the true frontier is found, the true, actual and estimated frontiers in will be plotted further below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def true_efficient_frontier():\n",
    "    n = 8\n",
    "    #returns = np.asmatrix(returns)\n",
    "    N = 100\n",
    "    mus = [10**(5.0 * t/N - 1.0) for t in range(N)]\n",
    "\n",
    "    # Convert to cvxopt matrices\n",
    "    S = opt.matrix(cov)\n",
    "    pbar = opt.matrix(mean)\n",
    "\n",
    "    # Create constraint matrices\n",
    "    G = -opt.matrix(np.eye(n))   # negative n x n identity matrix\n",
    "    h = opt.matrix(0.0, (n ,1))\n",
    "    A = opt.matrix(1.0, (1, n))\n",
    "    b = opt.matrix(1.0)\n",
    "\n",
    "    # Calculate efficient frontier weights using quadratic programming\n",
    "    portfolios = [solvers.qp(mu*S, -pbar, G, h, A, b)['x'] \n",
    "                for mu in mus]\n",
    "    \n",
    "    returns = [blas.dot(pbar, x) for x in portfolios]\n",
    "    risks = [np.sqrt(blas.dot(x, S*x)) for x in portfolios]\n",
    "    # sharpe = returns / risks\n",
    "\n",
    "    # sharpe_ratio.append(sharpe)\n",
    "\n",
    "    \n",
    "    m1 = np.polyfit(returns, risks, 2)\n",
    "    x1 = np.sqrt(m1[2] / m1[0])\n",
    "    \n",
    "    wt = solvers.qp(opt.matrix(x1 * S), -pbar, G, h, A, b)['x']\n",
    "    return np.asarray(wt), returns, risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cov' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-312c8c56c89e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_risks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_efficient_frontier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-4fc9f6c8808d>\u001b[0m in \u001b[0;36mtrue_efficient_frontier\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Convert to cvxopt matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cov' is not defined"
     ]
    }
   ],
   "source": [
    "weights, true_returns, true_risks = true_efficient_frontier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'true_risks' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-0af819589712>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_risks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y-o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#1f78b4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#fb9a99'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Actual Portfolios'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'upper left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_risks' is not defined"
     ]
    }
   ],
   "source": [
    "## Plotting \n",
    "fig = plt.figure(figsize = (14, 10))\n",
    "plt.plot(true_risks, true_returns, 'y-o', color = '#1f78b4')\n",
    "plt.scatter(np.sqrt(cov_mtx.to_numpy().diagonal()), mean, color = '#fb9a99', label = 'Actual Portfolios')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.title('True Efficient Frontier')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.ylabel('Return (Mean)')\n",
    "plt.xlabel('Risk (Standard Deviation)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual, Estimated, and True Frontier\n",
    "The visualisation below shows the true frontier (Blue), the estimated frontier (black) and the actual frontier (red). As we see, the actual frontier is a subset of non-optimal portfolios from the true frontier given that it uses a combination of real assets. The black frontier can follow a different path given that is generated from random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'true_risks' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-97b9c96a5f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Return (Mean)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Risk (Standard Deviation)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_risks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#1f78b4'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'True Frontier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrisk_data_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret_data_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#e31a1c'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Actual Frontier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimated_risks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimated_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Estimated Frontier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_risks' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 12))\n",
    "#plt.plot(stds, means, 'o')\n",
    "plt.ylabel('Return (Mean)')\n",
    "plt.xlabel('Risk (Standard Deviation)')\n",
    "plt.plot(true_risks, true_returns, color = '#1f78b4' , label = 'True Frontier')\n",
    "plt.plot(risk_data_actual, ret_data_actual, color = '#e31a1c', label = 'Actual Frontier')\n",
    "plt.plot(estimated_risks, estimated_returns, color = 'black', label = 'Estimated Frontier')\n",
    "plt.scatter(x = df['Volatility'], y = df['Returns'], c=  df['Sharpe Ratio'], cmap = 'coolwarm')\n",
    "\n",
    "#plt.scatter(np.sqrt(cov_mtx.to_numpy().diagonal()), mean, color = 'black')\n",
    "cb = plt.colorbar(shrink = 0.8, drawedges = False)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "plt.scatter(np.sqrt(cov_mtx.to_numpy().diagonal()), mean, color = '#fb9a99', label = 'Actual Portfolios')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Traditional Mean-Variance Analysis\n",
    "The traditional mean-variance analysis of Markowitz has some important weaknesses when applied naively in practice. They include the tendency to produce extreme portfolios combining extreme short positions with extreme long positions. As a result, portfolio managers (correctly) do not trust these extreme portfolios. This problem is invariably caused by estimation errors in the mean return vector and covariance matrix.\n",
    "\n",
    "Note that the blue curve above is the true frontier computed using the true mean vector and covariance matrix. The first observation is that the estimated frontiers are quite random and can differ greatly from the true frontier. They may lie below or above the true frontier or they may cross it and an investor who uses such an estimated frontier to make investment decisions may end up choosing a poor portfolio. The dashed red curves above are the realized frontiers that depict the true portfolio mean - volatility trade-off that results from making decisions based on the estimated frontiers. In contrast to the estimated frontiers, the realized frontiers must always lie below the true frontier. If the realised (estimated) frontiers were drawn multiple times some of the realized frontiers would lie very close to the true frontier and so in these cases an investor might do very well. But in other cases the realized frontier is far from the (generally unobtainable) true efficient frontier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In practice it is quite common for portfolio managers to manage and assess performance relative to a benchmark portfolio. This benchmark portfolio typically represents a particular asset class. A passive manager in this asset class might aim to replicate this benchmark where as an active manager would aim to outperform the benchmark. The mean-variance framework described in this project can be easily adapted to this latter case. In particular, the expected return is now replaced by the expected excess return where the excess return is $R^T>(w−w^B)$, the portfolio return minus the benchmark return where $w^B$ is used to denote the benchmark. Similarly the return variance is replaced by the variance of the tracking error, i.e. $Var(R^T>(w−w^B))$. This is still a convex quadratic optimization problem which is easy to solve. \n",
    "\n",
    "The nexts steps here are to investigte the Capital Asset Pricing Model (CAPM) which states that the tangency portfolio is held by all investors and because markets must clear, it can be identified that this portfolio is the market portfolio. The efficient frontier is then termed the capital market line. The CAPM result is one of the most famous results in all of finance and, even though it arises from a simple one-period model, it provides considerable insight to the problem of asset-pricing. \n",
    "\n",
    "The Black-Litterman model might also be studied next as it was developed in part to ameliorate the problem of mean-variance analysis producing extreme portfolios as outlined in this paper. However, it also allows investors to impose their own\n",
    "subjective views on the market-place and it has been very influential in the asset-allocation world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "#### Scenario Analysis\n",
    "https://corporatefinanceinstitute.com/resources/knowledge/modeling/scenario-analysis/  \n",
    "https://www.investopedia.com/terms/s/scenario_analysis.asp  \n",
    "  \n",
    "#### Pivot Tables\n",
    "https://en.wikipedia.org/wiki/Pivot_table  \n",
    "https://www.dataquest.io/blog/pandas-pivot-table/  \n",
    "\n",
    "#### The Greeks\n",
    "https://en.wikipedia.org/wiki/Greeks_(finance)  \n",
    "https://www.investopedia.com/terms/g/greeks.asp  \n",
    "https://www.optionsplaybook.com/options-introduction/option-greeks/  \n",
    "\n",
    "#### Modern Portfolio Theory\n",
    "https://www.investopedia.com/terms/m/modernportfoliotheory.asp  \n",
    "https://www.guidedchoice.com/video/dr-harry-markowitz-father-of-modern-portfolio-theory/  \n",
    "https://en.wikipedia.org/wiki/Modern_portfolio_theory  \n",
    "\n",
    "#### Efficient Frontier \n",
    "https://en.wikipedia.org/wiki/Efficient_frontier  \n",
    "https://towardsdatascience.com/understanding-efficient-frontier-46f1a429d526  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}